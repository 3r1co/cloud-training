{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This training is designed to give ISEN Students an introduction to Cloud technology. First, make sure to have your environment properly set up: Prerequisites Then you can continue with the Labs: Docker Kubernetes Cloud Architecture AWS","title":"Introduction"},{"location":"#introduction","text":"This training is designed to give ISEN Students an introduction to Cloud technology. First, make sure to have your environment properly set up: Prerequisites Then you can continue with the Labs: Docker Kubernetes Cloud Architecture AWS","title":"Introduction"},{"location":"aws/","text":"AWS Labs (1 hour) In this lab, you'll learn How to connect to AWS from your workstation How to design an Infrastructure as Code (IaC) file with the help of Troposphere How to deploy this file in your Development environment How to deliver this file through the Infrastructure Automation Pipeline to Production AWS Connection setup In this chapter, we'll explain you how to connect with the AWS CLI to your AWS Account. Create a user in IAM that has administrator privileges like described here Create a Access Key ID and Secret Access Key like described here In a terminal, type the following: aws configure Enter the Access Key ID and Secret Access Key you retrieved earlier. Enter eu-west-1 as default region and leave the default output empty. These credentials will be stored in %HOME%/.aws/credentials . Verify that you have access to the training account: aws ec2 describe - instances CloudFormation Let's now deploy your first resource in the development account. Download the following file to your \"CloudAwarenessLab\" folder: cloudformation.yaml This file deploys a single EC2 instance. Deploy the EC2 instance with the help of CloudFormation: aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack Wait until the stack is deployed and check if your instance is visible: aws ec2 describe - instances Follow up exercise Modify the CloudFormation template in order to add a Security Group which allows access on Port 443 to your EC2 instance. Troposphere Another way to generate CloudFormation templates is to use a framework for a programming language. One famous example is Troposphere, a Python Framework. The advantage of using a framework over bare CloudFormation is that you can use logic, conditions and loops when defining your infrastructure, so in short, it gives more flexibility when building it. In this example, we'll generate another EC2 instance. Download the following file to your \"CloudAwarenessLab\" folder: ec2_instance.py After you understood the logic of the file, let's deploy it now. Generate CloudFormation from the Python script: python ec2_instance . py > ec2_instance . yml Deploy the CloudFormation stack: aws cloudformation deploy --template-file ec2_instance.yml --stack-name <your-ldap-login>-ts-stack Follow up exercise Package the EC2 Instance in a Launch Configuration that is referenced by an Auto Scaling Group. You can find an example here . Deploy this template and verify that that your EC2 instance is backed by an Autoscaling group (have a look at the instance tags).","title":"Getting Started with AWS"},{"location":"aws/#aws-labs-1-hour","text":"In this lab, you'll learn How to connect to AWS from your workstation How to design an Infrastructure as Code (IaC) file with the help of Troposphere How to deploy this file in your Development environment How to deliver this file through the Infrastructure Automation Pipeline to Production","title":"AWS Labs (1 hour)"},{"location":"aws/#aws-connection-setup","text":"In this chapter, we'll explain you how to connect with the AWS CLI to your AWS Account. Create a user in IAM that has administrator privileges like described here Create a Access Key ID and Secret Access Key like described here In a terminal, type the following: aws configure Enter the Access Key ID and Secret Access Key you retrieved earlier. Enter eu-west-1 as default region and leave the default output empty. These credentials will be stored in %HOME%/.aws/credentials . Verify that you have access to the training account: aws ec2 describe - instances","title":"AWS Connection setup"},{"location":"aws/#cloudformation","text":"Let's now deploy your first resource in the development account. Download the following file to your \"CloudAwarenessLab\" folder: cloudformation.yaml This file deploys a single EC2 instance. Deploy the EC2 instance with the help of CloudFormation: aws cloudformation deploy --template-file cloudformation.yaml --stack-name <your-login>-stack Wait until the stack is deployed and check if your instance is visible: aws ec2 describe - instances","title":"CloudFormation"},{"location":"aws/#follow-up-exercise","text":"Modify the CloudFormation template in order to add a Security Group which allows access on Port 443 to your EC2 instance.","title":"Follow up exercise"},{"location":"aws/#troposphere","text":"Another way to generate CloudFormation templates is to use a framework for a programming language. One famous example is Troposphere, a Python Framework. The advantage of using a framework over bare CloudFormation is that you can use logic, conditions and loops when defining your infrastructure, so in short, it gives more flexibility when building it. In this example, we'll generate another EC2 instance. Download the following file to your \"CloudAwarenessLab\" folder: ec2_instance.py After you understood the logic of the file, let's deploy it now. Generate CloudFormation from the Python script: python ec2_instance . py > ec2_instance . yml Deploy the CloudFormation stack: aws cloudformation deploy --template-file ec2_instance.yml --stack-name <your-ldap-login>-ts-stack","title":"Troposphere"},{"location":"aws/#follow-up-exercise_1","text":"Package the EC2 Instance in a Launch Configuration that is referenced by an Auto Scaling Group. You can find an example here . Deploy this template and verify that that your EC2 instance is backed by an Autoscaling group (have a look at the instance tags).","title":"Follow up exercise"},{"location":"cicd/","text":"CI/CD Lab (30 Minutes) The goal of this exercise is to show you how to create a CI/CD Pipeline for containerized applications. At the end of this lab, you have a CI/CD pipeline, that * checks out your application source code * builds a Docker image * deploys this Docker image to Kubernetes","title":"CI/CD Lab (30 Minutes)"},{"location":"cicd/#cicd-lab-30-minutes","text":"The goal of this exercise is to show you how to create a CI/CD Pipeline for containerized applications. At the end of this lab, you have a CI/CD pipeline, that * checks out your application source code * builds a Docker image * deploys this Docker image to Kubernetes","title":"CI/CD Lab (30 Minutes)"},{"location":"cloud-architecture/","text":"Cloud Architecture and Migration Exercise (30 Minutes) Your Business Line has increasing demand from different goverments for a SaaS-based solution in order to easily manage digital documents. You want to leverage on the public cloud, but certain constraints need to be met: One component of your solution is using a HSM (Hardware Security Module) to encrypt PII (Personally Identifiable Information). This component must stay hosted in a Private Datacenter (1) One component is in maintenance mode since several years, but you'd like to reduce the hardware cost in your datacenter. It should therefore be migrated to the public cloud in the most cost efficient way. (2) One component is under active development, however, it is used in your solution, but also for a solution from another vertical which is deploying their solution also in-house at their customers. Therefore, it can not be locked in too far with a specific cloud provider (3) One component is completely owned by your team and it will not be used by other verticals. It's processing data 24/7 with a very steady workload. (4) One component is completely owned by your team and it will not be used by other verticals. It's sporadically used when a certain event occurs (5) Draw a diagram of a possible solution architecture, taking all the above constraints into account. Gather in teams of five persons and present your diagram at the end on a whiteboard.","title":"Cloud Architecture Exercise"},{"location":"cloud-architecture/#cloud-architecture-and-migration-exercise-30-minutes","text":"Your Business Line has increasing demand from different goverments for a SaaS-based solution in order to easily manage digital documents. You want to leverage on the public cloud, but certain constraints need to be met: One component of your solution is using a HSM (Hardware Security Module) to encrypt PII (Personally Identifiable Information). This component must stay hosted in a Private Datacenter (1) One component is in maintenance mode since several years, but you'd like to reduce the hardware cost in your datacenter. It should therefore be migrated to the public cloud in the most cost efficient way. (2) One component is under active development, however, it is used in your solution, but also for a solution from another vertical which is deploying their solution also in-house at their customers. Therefore, it can not be locked in too far with a specific cloud provider (3) One component is completely owned by your team and it will not be used by other verticals. It's processing data 24/7 with a very steady workload. (4) One component is completely owned by your team and it will not be used by other verticals. It's sporadically used when a certain event occurs (5) Draw a diagram of a possible solution architecture, taking all the above constraints into account. Gather in teams of five persons and present your diagram at the end on a whiteboard.","title":"Cloud Architecture and Migration Exercise (30 Minutes)"},{"location":"docker/","text":"Docker Lab (30 Minutes) The goal of this exercise is to build your first Docker container. At the end of the lab, you should have a functioning web server based on Node.JS packaged this web server in a Docker image a running a Docker container that you can access from your workstation To perform this lab: Verify that you can log in to the global Docker Registry: docker login Create a directory for this training on your Desktop (e.g. \"CloudAwarenessLab\"). Download the following files in this directory: Dockerfile (the file to build the Docker image) app.js (the application source code) In your terminal, position yourself in the directory: cd c : \\ Users \\ < loginldap > \\ Desktop \\ CloudAwarenessLab Open the previously downloaded file \"Dockerfile\" in an editor: the first line states FROM alpine:3.10 In case you wouldn't specify a tag (:3.10), Docker will default to \"latest\". It is a common best-practice to always specify a tag when referencing to an image. you'll also see one line stating ADD app.js /usr/local/bin In this step the source code of your Node.JS server is added into /usr/local/bin/ directory you'll also a line with the statement ENTRYPOINT . The entrypoint is the command that is run on your Docker container with the it is launched with the docker run command. Launch the image build process: docker build - t mywebserver : 1 . 0 . The Docker Engine has now built a new Docker image and you can find it in your local registry. To do so, type the following in your terminal: docker images Run the previously built image: docker run - d --rm -p 3000:3000 mywebserver:1.0 The id of the container is returned. The container is started in the background. Notes on the parameters: \" -d \" instructs Docker to run the container as a daemon, so in the background \" --rm \" instructs Docker to delete the container ones it is stopped. Like that, the local registry will not be poluted with \"intermediate\" containers \" -p 3000:3000 \" instructs Docker to expose the containers port 3000 on port 3000 on the host ( Attention : in our case, the host is the Minikube VM) You can check the logs of your running container with: docker logs < id of the container > Your container is running in the VM created by Minikube. As you exposed the port 3000 in the previous step, we now need to find the IP address if your Minikube VM: minikube ip In your browser, open http://minikube-ip:3000 . You should see \"Hello World\" now. Once you are satisfied with the result, you can transfer your image from local Docker registry to the global Docker registry. Do do so, tag your image and push it to docker.io: docker tag mywebserver : 1 . 0 docker . io / mywebserver : 1 . 0 docker push docker . io / mywebserver : 1 . 0 You can now stop your container (with the id of the container that was returned to you when you ran it) docker stop < id of the container > Follow up exercise (30 Minutes) After you learned how to build, run and push a Docker image, try to build the same application you saw here in another programming language (preferrably Java).","title":"Docker Lab"},{"location":"docker/#docker-lab-30-minutes","text":"The goal of this exercise is to build your first Docker container. At the end of the lab, you should have a functioning web server based on Node.JS packaged this web server in a Docker image a running a Docker container that you can access from your workstation To perform this lab: Verify that you can log in to the global Docker Registry: docker login Create a directory for this training on your Desktop (e.g. \"CloudAwarenessLab\"). Download the following files in this directory: Dockerfile (the file to build the Docker image) app.js (the application source code) In your terminal, position yourself in the directory: cd c : \\ Users \\ < loginldap > \\ Desktop \\ CloudAwarenessLab Open the previously downloaded file \"Dockerfile\" in an editor: the first line states FROM alpine:3.10 In case you wouldn't specify a tag (:3.10), Docker will default to \"latest\". It is a common best-practice to always specify a tag when referencing to an image. you'll also see one line stating ADD app.js /usr/local/bin In this step the source code of your Node.JS server is added into /usr/local/bin/ directory you'll also a line with the statement ENTRYPOINT . The entrypoint is the command that is run on your Docker container with the it is launched with the docker run command. Launch the image build process: docker build - t mywebserver : 1 . 0 . The Docker Engine has now built a new Docker image and you can find it in your local registry. To do so, type the following in your terminal: docker images Run the previously built image: docker run - d --rm -p 3000:3000 mywebserver:1.0 The id of the container is returned. The container is started in the background. Notes on the parameters: \" -d \" instructs Docker to run the container as a daemon, so in the background \" --rm \" instructs Docker to delete the container ones it is stopped. Like that, the local registry will not be poluted with \"intermediate\" containers \" -p 3000:3000 \" instructs Docker to expose the containers port 3000 on port 3000 on the host ( Attention : in our case, the host is the Minikube VM) You can check the logs of your running container with: docker logs < id of the container > Your container is running in the VM created by Minikube. As you exposed the port 3000 in the previous step, we now need to find the IP address if your Minikube VM: minikube ip In your browser, open http://minikube-ip:3000 . You should see \"Hello World\" now. Once you are satisfied with the result, you can transfer your image from local Docker registry to the global Docker registry. Do do so, tag your image and push it to docker.io: docker tag mywebserver : 1 . 0 docker . io / mywebserver : 1 . 0 docker push docker . io / mywebserver : 1 . 0 You can now stop your container (with the id of the container that was returned to you when you ran it) docker stop < id of the container >","title":"Docker Lab (30 Minutes)"},{"location":"docker/#follow-up-exercise-30-minutes","text":"After you learned how to build, run and push a Docker image, try to build the same application you saw here in another programming language (preferrably Java).","title":"Follow up exercise (30 Minutes)"},{"location":"kubernetes/","text":"Kubernetes Lab (30 Minutes) In this lab, you will deploy your previously created Docker image in Kubernetes. The goal of this lab is to show you the usage of Kubernetes deployments and services how to use Kubernetes scaling capabilites how to access a service deployed in Kubernetes Application Deployment Verify that you can access Kubernetes: kubectl version If you see a Server Version like below, it means your Kubernetes CLI can connect to your Kubernetes VM: $ kubectl version Client Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:52:43Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Server Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:44:49Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Download the following file to your \"CloudAwarenessLab\" folder: deployment.yaml Open the file in an editor and verify that the image: key is referencing your previously built image Deploy your application with the following command: kubectl apply - f deployment . yaml Verify that your application is running properly: kubectl get deployment You shoud now see one running Pod , which is scheduled by the Deployment that you just created. You can also check the running Pods in your Kubernetes cluster by typing: kubectl get pods This will give a list of running instances (a.k.a. Pods) of your application. Write down the name of the Pod, you'll need it later for reference. In order to access your application, you have to deploy a Kubernetes service. Download the following file your \"CloudAwarenessLab\" folder: service.yaml and apply the following command: kubectl apply - f service . yaml You have now deployed a so called NodePort Kubernetes Service . It opens a dedicated port on your Minikube VM, through which you can access the according service. You can find the associated port number by typing: kubectl get svc In the example below, the port number would be 31478 : $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 126d webserver-service NodePort 10 .98.147.142 <none> 80 :31478/TCP 4s In your browser, open the IP of your Minikube VM (which you retrieved in the previous lab) and add the port that you retrieved from the last command, e.g.: http://minikube-ip:31478 . You should see \"Hello World\" example from before, but it's hosted in Kubernetes. You should also see that the hostname is equal to the Pod name that you wrote down earlier. Application Scaling Now you'll see the scaling capabilities of Kubernetes. Enter the following command: kubectl scale deployment / webserver - deployment --replicas=3 With this command, you update the Kubernetes Deployment and instruct it to have a total of three replicas. Kubernetes will handle that by instantiating two additional Pods . Refresh your browser serveral times and monitor how the hostname of your microservice changes. Congratulations, you just learned how to scale a service in Kubernetes. Application Configuration For the next step, we we'll see how to configure an application in Kubernetes. You might have noticed that in the app.js file, we are defining an environment variable GREETING with the default value Hello World . In a first step, we will change the Kubernetes the Kubernetes deployment and add environment variable section the Pod template: kubectl edit deployment webserver - deployment and add the env section like described below: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING value : \"I'm configured now\" Refresh your browser, and see how to greeting changed. Now let's use another mean to configure our application: the Kubernetes ConfigMap . Download the sample ConfigMap to your \"CloudAwarenessLab\" folder: configmap.yaml This way, you can decouple the application from the deployment configuration and therefore ease the reusability of your application. You can deploy the ConfigMap with the following command: kubectl apply - f configmap . yaml Now, you'll have to modify your deployment in order to consume the ConfigMap: kubectl edit deployment webserver - deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING valueFrom : configMapKeyRef : name : webserver - configmap key : greeting Application Secrets Kubernetes also supports objects of the type Secret , that are meant to store sensitive data. Secrets can either be injected as environment variables or mounted in the Pods filesystem. As you already learned how to inject environment variables, let's now inject the Kubernetes secret as a file into our pod. Deploy a secret in our Kubernetes cluster: kubectl create secret generic webserver - secret --from-literal=secret.txt=\"Well done!\" Update your Pod definiton to mount the webserver-secret secret in /var/secret/ : kubectl edit deployment webserver - deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver volumeMounts : - name : webserver - secret mountPath : \"/var/secret\" readOnly : true volumes : - name : webserver - secret secret : secretName : webserver - secret Refresh your browser, and see how the greeting changed. Follow up exercise (30 Minutes) Try to launch a database in Kubernetes and connect an application with this database. A simple example can be found here . It's written in Node.JS and uses MongoDB.","title":"Kubernetes Lab"},{"location":"kubernetes/#kubernetes-lab-30-minutes","text":"In this lab, you will deploy your previously created Docker image in Kubernetes. The goal of this lab is to show you the usage of Kubernetes deployments and services how to use Kubernetes scaling capabilites how to access a service deployed in Kubernetes","title":"Kubernetes Lab (30 Minutes)"},{"location":"kubernetes/#application-deployment","text":"Verify that you can access Kubernetes: kubectl version If you see a Server Version like below, it means your Kubernetes CLI can connect to your Kubernetes VM: $ kubectl version Client Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:52:43Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Server Version: version.Info { Major: \"1\" , Minor: \"13\" , GitVersion: \"v1.13.10\" , GitCommit: \"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\" , GitTreeState: \"clean\" , BuildDate: \"2019-08-19T10:44:49Z\" , GoVersion: \"go1.11.13\" , Compiler: \"gc\" , Platform: \"linux/amd64\" } Download the following file to your \"CloudAwarenessLab\" folder: deployment.yaml Open the file in an editor and verify that the image: key is referencing your previously built image Deploy your application with the following command: kubectl apply - f deployment . yaml Verify that your application is running properly: kubectl get deployment You shoud now see one running Pod , which is scheduled by the Deployment that you just created. You can also check the running Pods in your Kubernetes cluster by typing: kubectl get pods This will give a list of running instances (a.k.a. Pods) of your application. Write down the name of the Pod, you'll need it later for reference. In order to access your application, you have to deploy a Kubernetes service. Download the following file your \"CloudAwarenessLab\" folder: service.yaml and apply the following command: kubectl apply - f service . yaml You have now deployed a so called NodePort Kubernetes Service . It opens a dedicated port on your Minikube VM, through which you can access the according service. You can find the associated port number by typing: kubectl get svc In the example below, the port number would be 31478 : $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 126d webserver-service NodePort 10 .98.147.142 <none> 80 :31478/TCP 4s In your browser, open the IP of your Minikube VM (which you retrieved in the previous lab) and add the port that you retrieved from the last command, e.g.: http://minikube-ip:31478 . You should see \"Hello World\" example from before, but it's hosted in Kubernetes. You should also see that the hostname is equal to the Pod name that you wrote down earlier.","title":"Application Deployment"},{"location":"kubernetes/#application-scaling","text":"Now you'll see the scaling capabilities of Kubernetes. Enter the following command: kubectl scale deployment / webserver - deployment --replicas=3 With this command, you update the Kubernetes Deployment and instruct it to have a total of three replicas. Kubernetes will handle that by instantiating two additional Pods . Refresh your browser serveral times and monitor how the hostname of your microservice changes. Congratulations, you just learned how to scale a service in Kubernetes.","title":"Application Scaling"},{"location":"kubernetes/#application-configuration","text":"For the next step, we we'll see how to configure an application in Kubernetes. You might have noticed that in the app.js file, we are defining an environment variable GREETING with the default value Hello World . In a first step, we will change the Kubernetes the Kubernetes deployment and add environment variable section the Pod template: kubectl edit deployment webserver - deployment and add the env section like described below: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING value : \"I'm configured now\" Refresh your browser, and see how to greeting changed. Now let's use another mean to configure our application: the Kubernetes ConfigMap . Download the sample ConfigMap to your \"CloudAwarenessLab\" folder: configmap.yaml This way, you can decouple the application from the deployment configuration and therefore ease the reusability of your application. You can deploy the ConfigMap with the following command: kubectl apply - f configmap . yaml Now, you'll have to modify your deployment in order to consume the ConfigMap: kubectl edit deployment webserver - deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver env : - name : GREETING valueFrom : configMapKeyRef : name : webserver - configmap key : greeting","title":"Application Configuration"},{"location":"kubernetes/#application-secrets","text":"Kubernetes also supports objects of the type Secret , that are meant to store sensitive data. Secrets can either be injected as environment variables or mounted in the Pods filesystem. As you already learned how to inject environment variables, let's now inject the Kubernetes secret as a file into our pod. Deploy a secret in our Kubernetes cluster: kubectl create secret generic webserver - secret --from-literal=secret.txt=\"Well done!\" Update your Pod definiton to mount the webserver-secret secret in /var/secret/ : kubectl edit deployment webserver - deployment And edit the file in the following way: spec : containers : - image : mywebserver : 1.0 imagePullPolicy : IfNotPresent name : webserver volumeMounts : - name : webserver - secret mountPath : \"/var/secret\" readOnly : true volumes : - name : webserver - secret secret : secretName : webserver - secret Refresh your browser, and see how the greeting changed.","title":"Application Secrets"},{"location":"kubernetes/#follow-up-exercise-30-minutes","text":"Try to launch a database in Kubernetes and connect an application with this database. A simple example can be found here . It's written in Node.JS and uses MongoDB.","title":"Follow up exercise (30 Minutes)"},{"location":"prerequisites/","text":"Prerequisites Please follow the instructions on this page carefully, as they will help you avoiding obstacles in the next exercices. The goal of the prerequisite step is to provide you a fully working development environment, containing Docker and Kubernetes. In order to achieve that, you'll be guided through the following steps: Install Chocolatey, a Package Manager for Windows With Chocolatey, you will install the following packages on your workstation: VirtualBox, a VM Manager Docker CLI and Kubernetes CLI Minikube, a tool that helps you installing a Docker and Kubernetes Development environment Python, a programming language that you'll need later in the course AWS CLI, you'll need it later in the course With Minikube, you will install a Virtual Machine in VirtualBox, containing Docker and Kubernetes The diagram on the bottom of this page is designed to help you to understand how Windows, your VM, Docker and Kubernetes are interacting. To perform this lab: Install Chocolatey according to the instructions here . You do not have to enter your email address in the first step. Launch a terminal with Windows Administrator rights and install Minikube, Kubectl (the Kubernetes CLI) and the Docker CLI with the help of Chocolatey: choco install - y python virtualbox minikube kubernetes - cli docker awscli Launch Minikube: minikube --docker-env HTTP_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env HTTPS_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env NO_PROXY=\"127.0.0.1,192.168.99.0/24,10.0.0.0/8\" start Notes on the parameters: As we are in a universtiy network, we need to configure docker engine in the virtual machine to perform outgoing internet connection through this proxy. Certain hosts do not need to be accessed through the proxy, which is configured through the \"NO_PROXY\" parameter. In our case, this is: localhost (127.0.0.1) the network between your local VMs (192.168.99.0/24), the network range normally used for intranet (10.0.0.0/8) In order for Minikube to download the according VM image, you may have to configure the proxy on your workstation as well: For Windows Terminal: set HTTP_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > set HTTPS_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > set NO_PROXY = 127 . 0 . 0 . 1 , 192 . 168 . 99 . 0 / 24 , 10 . 0 . 0 . 0 / 8 For Shell (Cygwin, Git Bash): export HTTP_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > export HTTPS_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > export NO_PROXY = 127 . 0 . 0 . 1 , 192 . 168 . 99 . 0 / 24 , 10 . 0 . 0 . 0 / 8 After Minikube is launched, it can be necessary to configure your Docker CLI and Kubernetes CLI on your workstation. This configuration is done through environment variables, which can be set with the following commands: This has to be done every time you open a new terminal. For Windows Terminal: @ FOR / f \" tokens=* \" % i IN ( ' minikube docker-env ' ) DO @ % i For Shell (Cygwin, Git Bash): eval ( minikube docker - env ) Verify that you can access the Docker CLI: docker info Verify that you can access the Kubernetes CLI: kubectl version Below you can see an diagram of your workstation setup, which should help you understanding how the different components are interacting:","title":"Prerequisites"},{"location":"prerequisites/#prerequisites","text":"Please follow the instructions on this page carefully, as they will help you avoiding obstacles in the next exercices. The goal of the prerequisite step is to provide you a fully working development environment, containing Docker and Kubernetes. In order to achieve that, you'll be guided through the following steps: Install Chocolatey, a Package Manager for Windows With Chocolatey, you will install the following packages on your workstation: VirtualBox, a VM Manager Docker CLI and Kubernetes CLI Minikube, a tool that helps you installing a Docker and Kubernetes Development environment Python, a programming language that you'll need later in the course AWS CLI, you'll need it later in the course With Minikube, you will install a Virtual Machine in VirtualBox, containing Docker and Kubernetes The diagram on the bottom of this page is designed to help you to understand how Windows, your VM, Docker and Kubernetes are interacting. To perform this lab: Install Chocolatey according to the instructions here . You do not have to enter your email address in the first step. Launch a terminal with Windows Administrator rights and install Minikube, Kubectl (the Kubernetes CLI) and the Docker CLI with the help of Chocolatey: choco install - y python virtualbox minikube kubernetes - cli docker awscli Launch Minikube: minikube --docker-env HTTP_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env HTTPS_PROXY=\"http://<isen-proxy-host>:<isen-proxy-port>\" --docker-env NO_PROXY=\"127.0.0.1,192.168.99.0/24,10.0.0.0/8\" start Notes on the parameters: As we are in a universtiy network, we need to configure docker engine in the virtual machine to perform outgoing internet connection through this proxy. Certain hosts do not need to be accessed through the proxy, which is configured through the \"NO_PROXY\" parameter. In our case, this is: localhost (127.0.0.1) the network between your local VMs (192.168.99.0/24), the network range normally used for intranet (10.0.0.0/8) In order for Minikube to download the according VM image, you may have to configure the proxy on your workstation as well: For Windows Terminal: set HTTP_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > set HTTPS_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > set NO_PROXY = 127 . 0 . 0 . 1 , 192 . 168 . 99 . 0 / 24 , 10 . 0 . 0 . 0 / 8 For Shell (Cygwin, Git Bash): export HTTP_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > export HTTPS_PROXY = http : //< isen - proxy - host > : < isen - proxy - port > export NO_PROXY = 127 . 0 . 0 . 1 , 192 . 168 . 99 . 0 / 24 , 10 . 0 . 0 . 0 / 8 After Minikube is launched, it can be necessary to configure your Docker CLI and Kubernetes CLI on your workstation. This configuration is done through environment variables, which can be set with the following commands: This has to be done every time you open a new terminal. For Windows Terminal: @ FOR / f \" tokens=* \" % i IN ( ' minikube docker-env ' ) DO @ % i For Shell (Cygwin, Git Bash): eval ( minikube docker - env ) Verify that you can access the Docker CLI: docker info Verify that you can access the Kubernetes CLI: kubectl version Below you can see an diagram of your workstation setup, which should help you understanding how the different components are interacting:","title":"Prerequisites"}]}